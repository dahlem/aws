# -*- org-export-babel-evaluate: nil -*-
# -*- org-confirm-babel-evaluate: nil -*-
#+TITLE:     AWS Setups
#+AUTHOR:    Dominik Dahlem
#+EMAIL:     dominik.dahlem@gmail.com
#+DATE:      2017-03-09 Thu
#+LANGUAGE:  en

* Prequel
The documentation of the following workflow is done using org-mode
which is an emacs package for literal programming and more. The
workflow is documented in a serial fashion with all the scripts
embedded. In principle it can be opened in any text editor, however,
to see all the annotations Emacs should be used.

This org file documents the entirety of the AWS setup for GPU
computing. The following sections provide the source-code snippets in
various programming languages to accomplish this.

** Variable Declarations
You can re-run this subtree by executing `org-babel-execute-subtree'
in order to set the variables to your environment. Change the code
below to get directories depending on who you are. Also, you can run
the command `org-babel-execute-subtree' with C-c C-v s.

*** Directories

Let's set up the directories we will be using. I would keep an AWS
folder with sub-directories for all cluster setups respectively.

#+name: baseDir
#+BEGIN_SRC sh
  pwd
#+END_SRC

#+name: dataDir
#+begin_src sh :var baseDir=baseDir
echo ${baseDir}/data
#+end_src

#+name: scriptsDir
#+begin_src sh :var baseDir=baseDir
echo ${baseDir}/scripts
#+end_src

We create all directories, which we only need to do when we set up the
project.

#+BEGIN_SRC sh :var scriptsDir=scriptsDir :var dataDir=dataDir :results none
  mkdir -p ${scriptsDir}
  mkdir -p ${dataDir}
#+END_SRC

* Setup
In order to setup the EC2 instance, we first create the cluster
environment and then install the desired software in order to create
an AMI image first. In subsequent steps, we can use our AMI image
directly.

** EC2 instance
We are mostly interested in P2 instances, because they are dedicated
GPU computing resources. They come in various sizes, and we might only
need a single instance to conduct the work. However, the following
scripts can be used for any EC2 instance types of course.

*** Configuration
Most of the EC2 environment configuration is taken from Jeremy
Howard's deep learning course. I changed the script a bit to
accommodate creating spot instances instead of an on-demand instance.

The following variables are needed.

#+name: instanceType
 : p2.xlarge

For spot instances we give a max price to adhere to in order to
request an instance.

#+name: maxPrice
 : 0.25

We work off an AWS supplied image of Ubuntu 16.04 (ami-405f7226 in the
eu-west-1 region). If you launch this script in a different
environment you'd to find a corresponding AMI ID. The script below was
used to create a dedicated deep learning environment
(ami-c21b31a4) that includes several python-based deep learning
libraries, i.e., pytorch, theano, tensorflow, and keras. Those
libraries are installed in two Anaconda environments, one for python
2.7 (py27) and one for python 3.5 (py35). We also loaded up a
deepspeech environment with custom pytorch bindings for speech to text
transcriptions in py27.

#+name: ami
 : ami-405f7226

We can specify the default region for our EC2 instances.

#+name: region
 : eu-west-1

Further to this, we might fix the availability zone in order to take
advantage of the stability of the market for spot instances. You could
run the [[#sec:util-price-hist]] script in order to find out which
availability zone is more robust to price changes.

#+name: az
 : eu-west-1a

The following variable is the profile name.

#+name: name
 : ddahlem

#+name: cidr
 : 0.0.0.0/0

The following variables are used for tagging the resources for billing purposes.

#+name: bu
 : BU

#+name: application
 : App

#+name: stack
 : Dev

#+name: owner
 : ddahlem

#+BEGIN_SRC sh :tangle scripts/tag4billing.sh :var bu=bu :var application=application :var stack=stack :var owner=owner :var name=name
RESOURCE=$1

aws ec2 create-tags --resources ${RESOURCE} --tags Key=BusinessUnit,Value=${bu} --profile ${name}
aws ec2 create-tags --resources ${RESOURCE} --tags Key=Application,Value=${application} --profile ${name}
aws ec2 create-tags --resources ${RESOURCE} --tags Key=Stack,Value=${stack} --profile ${name}
aws ec2 create-tags --resources ${RESOURCE} --tags Key=Owner,Value=${owner} --profile ${name}
#+END_SRC

The following script just creates a JSON launch specification to
create spot instances. Since we mostly use m4 or p2 instances, we can
enable EBS optimisation without incurring an extra cost. Check the AWS
documentation to make sure that no additional cost is added by
enabling this feature. Also, we enable detailed monitoring.

#+BEGIN_SRC python :tangle scripts/spec.py
import json, sys

print(json.dumps({
    'ImageId': sys.argv[1],
    'KeyName': sys.argv[2],
    'SecurityGroupIds': list(map(str.strip, sys.argv[3].split(','))),
    'InstanceType': sys.argv[4],
    'SubnetId': sys.argv[5],
    'BlockDeviceMappings': [
        {
            'DeviceName': '/dev/sda1',
            'Ebs': {
                'VolumeSize': 128,
                'VolumeType': 'gp2'
            }
        }
    ],
    'EbsOptimized': True,
    'Monitoring': {
        'Enabled': True
    }
}, indent=4))
#+END_SRC

#+BEGIN_SRC python :tangle scripts/cleanup.py
import csv, sys

if len(sys.argv) == 2:
    envsFile = csv.reader(open(sys.argv[1], 'r'), delimiter='=')

    envsDict = {}
    for e in envsFile:
        envsDict[e[0]] = e[1]

    print('set -x')
    if 'assocId' in envsDict:
        print('aws ec2 disassociate-address --profile {0:s} --association-id {1:s}'.format(envsDict['name'], envsDict['assocId']))
    if 'allocAddr' in envsDict:
        print('aws ec2 release-address --profile {0:s} --allocation-id {1:s}'.format(envsDict['name'], envsDict['allocAddr']))
    if 'instanceId' in envsDict:
        print('aws ec2 terminate-instances --profile {0:s} --instance-ids {1:s}'.format(envsDict['name'], envsDict['instanceId']))
        print('aws ec2 wait instance-terminated --profile {0:s} --instance-ids {1:s}'.format(envsDict['name'], envsDict['instanceId']))
    if 'securityGroupId' in envsDict:
        print('aws ec2 delete-security-group --profile {0:s} --group-id {1:s}'.format(envsDict['name'], envsDict['securityGroupId']))
    if 'routeTableAssoc' in envsDict:
        print('aws ec2 disassociate-route-table --profile {0:s} --association-id {1:s}'.format(envsDict['name'], envsDict['routeTableAssoc']))
    if 'routeTableId' in envsDict:
        print('aws ec2 delete-route-table --profile {0:s} --route-table-id {1:s}'.format(envsDict['name'], envsDict['routeTableId']))
    if 'internetGatewayId' in envsDict and 'vpcId' in envsDict:
        print('aws ec2 detach-internet-gateway --profile {0:s} --internet-gateway-id {1:s} --vpc-id {2:s}'.format(envsDict['name'], envsDict['internetGatewayId'], envsDict['vpcId']))
        print('aws ec2 delete-internet-gateway --profile {0:s} --internet-gateway-id {1:s}'.format(envsDict['name'], envsDict['internetGatewayId']))
    if 'subnetId' in envsDict:
        print('aws ec2 delete-subnet --profile {0:s} --subnet-id {1:s}'.format(envsDict['name'], envsDict['subnetId']))
    if 'vpcId' in envsDict:
        print('aws ec2 delete-vpc --profile {0:s} --vpc-id {1:s}'.format(envsDict['name'], envsDict['vpcId']))
#+END_SRC

The following script is mainly taken from Jeremy Howard with some
modifications to launch spot instances and to differentiate between
AWS profiles.

#+BEGIN_SRC sh :tangle scripts/setup.sh :var instanceType=instanceType :var ami=ami :var name=name :var cidr=cidr :var scriptsDir=scriptsDir :var dataDir=dataDir :var maxPrice=maxPrice :var az=az
set -x ## print the commands
set -e ## fail script if one command returns zero

echo name=${name} > ${dataDir}/${name}-envs.txt
echo instanceType=${instanceType} >> ${dataDir}/${name}-envs.txt

vpcId=$(aws ec2 create-vpc --cidr-block 10.0.0.0/28 --query 'Vpc.VpcId' --output text --profile ${name})
echo vpcId=${vpcId} >> ${dataDir}/${name}-envs.txt
aws ec2 create-tags --resources ${vpcId} --tags Key=Name,Value=${name} --profile ${name}
${scriptsDir}/tag4billing.sh ${vpcId}

aws ec2 modify-vpc-attribute --vpc-id ${vpcId} --enable-dns-support "{\"Value\":true}" --profile ${name}
aws ec2 modify-vpc-attribute --vpc-id ${vpcId} --enable-dns-hostnames "{\"Value\":true}" --profile ${name}

internetGatewayId=$(aws ec2 create-internet-gateway --query 'InternetGateway.InternetGatewayId' --output text --profile ${name})
echo internetGatewayId=${internetGatewayId} >> ${dataDir}/${name}-envs.txt
aws ec2 create-tags --resources ${internetGatewayId} --tags --tags Key=Name,Value=${name}-gateway --profile ${name}
${scriptsDir}/tag4billing.sh ${internetGatewayId}

aws ec2 attach-internet-gateway --internet-gateway-id ${internetGatewayId} --vpc-id ${vpcId} --profile ${name}

subnetId=$(aws ec2 create-subnet --vpc-id ${vpcId} --availability-zone ${az} --cidr-block 10.0.0.0/28 --query 'Subnet.SubnetId' --output text --profile ${name})
echo subnetId=${subnetId} >> ${dataDir}/${name}-envs.txt
aws ec2 create-tags --resources ${subnetId} --tags --tags Key=Name,Value=${name}-subnet --profile ${name}
${scriptsDir}/tag4billing.sh ${subnetId}

routeTableId=$(aws ec2 create-route-table --vpc-id ${vpcId} --query 'RouteTable.RouteTableId' --output text --profile ${name})
echo routeTableId=${routeTableId} >> ${dataDir}/${name}-envs.txt
aws ec2 create-tags --resources ${routeTableId} --tags --tags Key=Name,Value=${name}-route-table --profile ${name}
${scriptsDir}/tag4billing.sh ${routeTableId}

routeTableAssoc=$(aws ec2 associate-route-table --route-table-id ${routeTableId} --subnet-id ${subnetId} --output text --profile ${name})
echo routeTableAssoc=${routeTableAssoc} >> ${dataDir}/${name}-envs.txt
aws ec2 create-route --route-table-id ${routeTableId} --destination-cidr-block 0.0.0.0/0 --gateway-id ${internetGatewayId} --profile ${name}

securityGroupId=$(aws ec2 create-security-group --group-name ${name}-security-group --description "SG for ddahlem GPU machine" --vpc-id ${vpcId} --query 'GroupId' --output text --profile ${name})
echo securityGroupId=${securityGroupId} >> ${dataDir}/${name}-envs.txt
aws ec2 create-tags --resources ${securityGroupId} --tags --tags Key=Name,Value=${name}-security-group --profile ${name}
${scriptsDir}/tag4billing.sh ${securityGroupId}

# ssh
aws ec2 authorize-security-group-ingress --group-id ${securityGroupId} --protocol tcp --port 22 --cidr ${cidr} --profile ${name}

# jupyter notebook
aws ec2 authorize-security-group-ingress --group-id ${securityGroupId} --protocol tcp --port 8888-8898 --cidr ${cidr} --profile ${name}

# tensorboard
aws ec2 authorize-security-group-ingress --group-id ${securityGroupId} --protocol tcp --port 6006 --cidr ${cidr} --profile ${name}

if [ ! -d ~/.ssh ]
then
    mkdir ~/.ssh
fi

if [ ! -f ~/.ssh/aws-key-${name}.pem ]
then
    aws ec2 create-key-pair --key-name aws-key-${name} --query 'KeyMaterial' --output text --profile ${name} > ~/.ssh/aws-key-${name}.pem
    chmod 400 ~/.ssh/aws-key-${name}.pem
fi

python ${scriptsDir}/spec.py ${ami} aws-key-${name} "${securityGroupId}" ${instanceType} ${subnetId} > ${dataDir}/launch-spec.json
instanceReqId=$(aws ec2 request-spot-instances --spot-price ${maxPrice} --availability-zone-group ${az} --instance-count 1 --type "one-time" --launch-specification file://${dataDir}/launch-spec.json --query 'SpotInstanceRequests[0].SpotInstanceRequestId' --output text --profile ${name})
echo instanceReqId=${instanceReqId} >> ${dataDir}/${name}-envs.txt

echo Waiting for instance start...
aws ec2 wait spot-instance-request-fulfilled --profile ${name} --spot-instance-request-ids ${instanceReqId}
instanceId=$(aws ec2 describe-spot-instance-requests --profile ${name} --output text --filter "Name=spot-instance-request-id,Values=${instanceReqId}" --query 'SpotInstanceRequests[0].InstanceId')
echo instanceId=${instanceId} >> ${dataDir}/${name}-envs.txt

aws ec2 create-tags --resources ${instanceId} --tags Key=Name,Value=${name}-ec2-node --profile ${name}
${scriptsDir}/tag4billing.sh ${instanceId}

allocAddr=$(aws ec2 allocate-address --domain vpc --query 'AllocationId' --output text --profile ${name})
echo allocAddr=${allocAddr} >> ${dataDir}/${name}-envs.txt

aws ec2 wait instance-running --instance-ids ${instanceId} --profile ${name}
sleep 10 # wait for ssh service to start running too
assocId=$(aws ec2 associate-address --instance-id ${instanceId} --allocation-id ${allocAddr} --query 'AssociationId' --output text --profile ${name})
echo assocId=${assocId} >> ${dataDir}/${name}-envs.txt
instanceUrl=$(aws ec2 describe-instances --instance-ids ${instanceId} --query 'Reservations[0].Instances[0].PublicDnsName' --output text --profile ${name})
echo instanceUrl=${instanceUrl} >> ${dataDir}/${name}-envs.txt

# save commands to file
echo \# Connect to your instance: > ${dataDir}/${name}-commands.txt
echo ssh -i ~/.ssh/aws-key-${name}.pem ubuntu@${instanceUrl} >> ${dataDir}/${name}-commands.txt
echo \# Stop your instance: : >> ${dataDir}/${name}-commands.txt
echo aws ec2 stop-instances --instance-ids ${instanceId} --profile ${name} >> ${dataDir}/${name}-commands.txt
echo \# Start your instance: >> ${dataDir}/${name}-commands.txt
echo aws ec2 start-instances --instance-ids ${instanceId} --profile ${name} >> ${dataDir}/${name}-commands.txt
echo \# Reboot your instance: >> ${dataDir}/${name}-commands.txt
echo aws ec2 reboot-instances --instance-ids ${instanceId} --profile ${name} >> ${dataDir}/${name}-commands.txt
echo ""

# create image
echo aws ec2 create-image --instance-id ${instanceId} --name "Deep Learning Server" --description "An AMI for Deep Learning on NVIDIA GPUs" --block-device-mappings "[{\"DeviceName\": \"/dev/sda1\",\"Ebs\":{\"VolumeSize\":128, \"VolumeType\": \"gp2\"}}]" --profile ${name} > ${scriptsDir}/${name}-create-image.sh

# create cleanup script
python ${scriptsDir}/cleanup.py ${dataDir}/${name}-envs.txt > ${scriptsDir}/cleanup.sh

chmod +x ${scriptsDir}/*.sh

echo All done. Find all you need to connect in the ${name}-commands.txt file
echo Connect to your instance: ssh -i ~/.ssh/aws-key-${name}.pem ubuntu@${instanceUrl}
#+END_SRC

*** System Installation
**** Environment Setup
This script sets up the Ubuntu environment with the appropriate
libraries to perform deep learning model training using python using
NVIDIA tools. It also sets up Anaconda with dedicated
environments. For 'ease of use' we install python DNN libraries using
anaconda in the selected environment. For special purpose tasks, e.g.,
speech to text, we use a dedicated environment with concrete supported
versions of the related libraries.

We also make a distinction between gcc-4 and gcc-5. Main Ubuntu
libraries are build using gcc-5 and the user-level libraries that live
within anaconda are build using gcc-4. For this reason we need to
select the appropriate version during the setup script.

The following script sets up the Ubuntu server including the cuda
environment

#+BEGIN_SRC sh :tangle scripts/system-setup.sh
set -x
set -e

## system update
sudo locale-gen en_IE.UTF-8
sudo apt-get update
sudo apt-get --assume-yes upgrade
sudo apt-get --assume-yes install build-essential gcc-5 g++-5 make binutils cmake sox gcc-4.9 g++-4.9 gfortran-4.9 linux-source linux-headers-$(uname -r) libav-tools gfortran-4.9

## set the gcc version
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 10
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 20

sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.9 10
sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 20

sudo update-alternatives --install /usr/bin/cc cc /usr/bin/gcc 30
sudo update-alternatives --set cc /usr/bin/gcc

sudo update-alternatives --install /usr/bin/c++ c++ /usr/bin/g++ 30
sudo update-alternatives --set c++ /usr/bin/g++

sudo update-alternatives --set gcc /usr/bin/gcc-4.9
sudo update-alternatives --set g++ /usr/bin/g++-4.9

mkdir ~/downloads
cd ~/downloads

## CUDA installation
## Access to CUDA packages
CUDA_REPO_PKG=cuda-repo-ubuntu1604_8.0.61-1_amd64.deb
wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/${CUDA_REPO_PKG} -O ${CUDA_REPO_PKG}
sudo dpkg -i ${CUDA_REPO_PKG}

sudo apt-get update
sudo apt-get install -y cuda

echo "export PATH=/usr/local/cuda/bin:\$PATH" >> ~/.bashrc
echo "export CUDA_HOME=/usr/local/cuda/bin:\$PATH" >> ~/.bashrc
echo "export LD_LIBRARY_PATH=${CUDA_HOME}/lib64:$LD_LIBRARY_PATH" >> ~/.bashrc
source ~/.bashrc

## install libcudnn
read -p "Press [Enter] once you downloaded cudnn.tgz into ~/downloads..."
tar xvzf cudnn.tgz
sudo cp cuda/include/* /usr/local/cuda/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64

sudo reboot
#+END_SRC

The following script sets up a desired anaconda environment for a
particular python version.

#+BEGIN_SRC sh :tangle scripts/anaconda-env-setup.sh
environment=$1
pythonVersion=$2

set -x
set -e

source ~/.bashrc

conda create -y -n ${environment} python=${pythonVersion} anaconda
source activate ${environment}
conda upgrade -y --all
conda install -y bcolz
conda install -y pytorch torchvision cuda80 -c soumith
pip install theano
pip install keras
pip install hyperas
pip install tensorflow-gpu
pip install environment_kernels
source deactivate ${environment}
#+END_SRC

The Jupyter setup facilitates choosing a kernel as in switching
between the Anaconda environments. However, the Jupyter server runs
off the main environment.

#+BEGIN_SRC sh :tangle scripts/anaconda-setup.sh :var scriptsDir=scriptsDir
set -x
set -e

mkdir ~/downloads
cd ~/downloads

## Anaconda installation
wget "https://repo.continuum.io/archive/Anaconda2-4.3.0-Linux-x86_64.sh"
bash Anaconda2-4.3.0-Linux-x86_64.sh -b
echo "export PATH=\"$HOME/anaconda2/bin:\$PATH\"" >> ~/.bashrc
source ~/.bashrc

## install into all environments
echo "[global]
device = gpu
floatX = float32
[cuda]
root = /usr/local/cuda" > ~/.theanorc

mkdir ~/.keras
echo '{
    "image_dim_ordering": "th",
    "epsilon": 1e-07,
    "floatx": "float32",
    "backend": "theano"
}' > ~/.keras/keras.json

${scriptsDir}/anaconda-env-setup.sh py35 3.5

## configure jupyter and prompt for password
source activate py35
jupyter notebook --generate-config
jupass=$(python -c "from notebook.auth import passwd; print(passwd())")
echo "c.NotebookApp.password = u'"${jupass}"'" >> $HOME/.jupyter/jupyter_notebook_config.py
echo "c.NotebookApp.ip = '*'" >> $HOME/.jupyter/jupyter_notebook_config.py
echo "c.NotebookApp.open_browser = False" >> $HOME/.jupyter/jupyter_notebook_config.py
echo "c.NotebookApp.kernel_spec_manager_class = 'environment_kernels.EnvironmentKernelSpecManager'"  >> $HOME/.jupyter/jupyter_notebook_config.py
#+END_SRC

According to the AWS documentation we can optimise the GPU settings as
follows:

#+BEGIN_SRC sh :tangle scripts/gpu-settings.sh
sudo nvidia-smi -pm 1
sudo nvidia-smi --auto-boost-default=0
sudo nvidia-smi -ac 2505,875
#+END_SRC

**** Deepspeech Torch setup
This installation guide is taken from Torch, but for posterity we
transcribe it here.

Torch can be installed to your home folder in ~/torch by running these
three commands:

#+BEGIN_SRC sh :tangle scripts/torch.sh
cd ~/
git clone https://github.com/torch/distro.git ~/torch --recursive
cd ~/torch; bash install-deps;
./install.sh -b
source ~/.bashrc
luarocks install cutorch
luarocks install cunn
luarocks install cunnx
#+END_SRC

Optim: numeric optimization package for Torch:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install optim
#+END_SRC

rnn: Recurrent Neural Network library for Torch7's nn:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install rnn
#+END_SRC

lua---nnx: An extension to Torch7's nn package:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install nnx
#+END_SRC

xlua: A set of useful extensions to Lua:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install xlua
#+END_SRC

threads: Threads for Lua and LuaJIT:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install threads
#+END_SRC

lua---parallel: A (simple) parallel computing framework for Lua:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install parallel
#+END_SRC

nngraph: Graph Computation for nn:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install nngraph
#+END_SRC

It is also suggested to update the following libraries:

#+BEGIN_SRC sh :tangle scripts/torch.sh
luarocks install nn
luarocks install dpnn
#+END_SRC

LMDB: LMDB for Torch used for online training:

#+BEGIN_SRC sh :tangle scripts/torch.sh
mkdir ~/githubs
cd ~/githubs
git clone https://github.com/LMDB/lmdb
cd lmdb/libraries/liblmdb/
make
sudo make install

cd ~/githubs
git clone https://github.com/eladhoffer/lmdb.torch
cd lmdb.torch
luarocks make
sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev
#+END_SRC

Audio Library for Torch: Audio Library for Torch:

#+BEGIN_SRC sh :tangle scripts/deepspeech-torch.sh
luarocks install http://raw.githubusercontent.com/baidu-research/warp-ctc/master/torch_binding/rocks/warp-ctc-scm-1.rockspec

sudo apt-get install -y libfftw3-dev sox libsox-dev libsox-fmt-all
luarocks install https://raw.githubusercontent.com/soumith/lua---audio/master/audio-0.1-0.rockspec
luarocks install tds

mkdir ~/projects
cd ~/projects
git clone https://github.com/SeanNaren/CTCSpeechRecognition.git
#+END_SRC

*** Test Deep Neural network libraries

We only need to test the deep learning libraries when the system is
set up. However, these scripts can be executed any time one wishes to
test an installation.

#+BEGIN_SRC sh :tangle scripts/test-keras.sh
source activate py35
curl -sSL https://github.com/fchollet/keras/raw/master/examples/mnist_mlp.py | python
source deactivate py35
#+END_SRC

#+BEGIN_SRC sh :tangle scripts/test-tensorflow.sh
source activate py35
curl -sSL https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/tutorials/mnist/input_data.py|python
curl -sSL https://github.com/tensorflow/tensorflow/raw/master/tensorflow/examples/tutorials/mnist/mnist_softmax.py|python
source deactivate py35
#+END_SRC

#+BEGIN_SRC sh :tangle scripts/test-deepspeech.sh
source activate py27
cd ~/githubs/deepspeech.pytorch
cd data; PYTHONPATH=~/githubs/deepspeech.pytorch python an4.py
cd ~/githubs/deepspeech.pytorch
python train.py --train_manifest data/train_manifest.csv --val_manifest data/val_manifest.csv
source deactivate py27
#+END_SRC

*** Data Preparation and Training

Before doing anything data-specific we might wish to create a data
volume, attach it and download all data and perform the computation on
the mounted volume [[#sec:util-attach-vol]].

**** Download data
Convert flac to wav files

#+BEGIN_SRC sh :tangle scripts/flac2wav.sh
flacfile=$1
avconv -y -f flac -i $flacfile -ab 64k -ac 1 -ar 16000 -f wav "${flacfile%.*}.wav"
#+END_SRC

#+BEGIN_SRC sh :tangle scripts/sph2wav.sh
sphfile=$1
sox -q -t wav "${sphfile%.%}.wav" -c 1 -B -r 16000 -b 16 -t sph ${sphfile}
#+END_SRC

Download the LibriSpeech dataset, expand and convert to wav files.

#+BEGIN_SRC sh :tangle scripts/librispeech-download.sh :var scriptsDir=scriptsDir
base="http://www.openslr.org/resources/12/"
for s in 'dev-clean' 'dev-other' 'test-clean' 'test-other' 'train-clean-100' 'train-clean-360' 'train-other-500'
do
    linkname="${base}/${s}.tar.gz"
    echo $linkname
    wget -c $linkname
done

for s in 'dev-clean' 'dev-other' 'test-clean' 'test-other' 'train-clean-100' 'train-clean-360' 'train-other-500'
do
    tar -xzvf $s.tar.gz
done

find . -type f -name "*.flac" |xargs -n 1 -P $(nproc) -I {} ${scriptsDir}/flac2wav.sh {}

mkdir -p {dev,test,train}

find dev-clean -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} dev/
find dev-clean -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} dev/
find dev-other -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} dev/
find dev-other -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} dev/

find test-clean -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} test/
find test-clean -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} test/
find test-other -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} other/
find test-other -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} other/

find train-clean-100 -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} train/
find train-clean-100 -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} train/
find train-clean-360 -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} train/
find train-clean-360 -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} train/
find train-other-500 -name "*.wav" |xargs -n 1 -P $(nproc) -I {} cp {} train/
find train-other-500 -name "*.txt" |xargs -n 1 -P $(nproc) -I {} cp {} train/
#+END_SRC

Extract the transcriptions, because for every data source they are
collated into a single file.

#+BEGIN_SRC python :tangle scripts/libriTxt.py
import argparse
import os

def main(txtFile):
    for line in open(txtFile):
        split = line.strip().split()
        file_id = split[0]
        label = ' '.join(split[1:]).lower()
        output_file = file_id + '.txt'
        with open(output_file, 'w') as out_file:
            out_file.write(label)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('txt_file', type=str,
                        help='Path to overall transcription file')
    args = parser.parse_args()
    main(args.txt_file)
#+END_SRC

Execute this script in the man LibriSpeech folder.

#+BEGIN_SRC sh :tangle scripts/libriTxt-trans.sh :var scriptsDir=scriptsDir
cd dev
find . -type f -name "*.trans.txt" | xargs -n 1 -P $(nproc) -I {} python ${scriptsDir}/libriTxt.py {}
rm *.trans.txt
cd ../test
find . -type f -name "*.trans.txt" | xargs -n 1 -P $(nproc) -I {} python ${scriptsDir}/libriTxt.py {}
rm *.trans.txt
cd ../train
find . -type f -name "*.trans.txt" | xargs -n 1 -P $(nproc) -I {} python ${scriptsDir}/libriTxt.py {}
rm *.trans.txt
#+END_SRC

Download the TED-LIUM data.

#+BEGIN_SRC sh :tangle scripts/tedlium-download.sh :var scriptsDir=scriptsDir
wget http://www.openslr.org/resources/19/TEDLIUM_release2.tar.gz
tar xzf TEDLIUM_release2.tar.gz
find . -type f -name "*.sph" |xargs -n 1 -P $(nproc) -I {} ${scriptsDir}/sph2wav.sh {}
#+END_SRC

The following script up/down-tempos the wav files. It takes the following parameters
./tempo. <F> <T> <T> <S>, where
F: is the wav file
T: is the tempo factor
V: is a volume setting, e.g., 0.95
S: is the string representing the tempo setting, e.g., for 1.3 it could be set to 13

This script also expects a matching transcription file, which is copied.

#+BEGIN_SRC sh :tangle scripts/tempo.sh
F=$1
T=$2
V=$3
S=$4

set -e
sox -v ${V} ${F} $(dirname ${F})/$(basename ${F} ".wav")_t${S}.wav tempo ${T}
cp $(dirname ${F})/$(basename ${F} ".wav").txt $(dirname ${F})/$(basename ${F} ".wav")_t${S}.txt
#+END_SRC

The following script finds all wav files in the current directory and
creates up/down tempo versions of it. Before starting with this we
need to create an original file list, i.e., 

#+BEGIN_SRC sh :tangle scripts/orig-files.sh
find . -type f -name "*.wav" > filelist
#+END_SRC

#+BEGIN_SRC sh :tangle scripts/up-down-tempo.sh :var scriptsDir=scriptsDir
xargs -a filelist -n 1 -P $(nproc) -I {} ${scriptsDir}/tempo.sh {} 0.9 0.95 09
xargs -a filelist -n 1 -P $(nproc) -I {} ${scriptsDir}/tempo.sh {} 1.1 0.95 11
xargs -a filelist -n 1 -P $(nproc) -I {} ${scriptsDir}/tempo.sh {} 1.5 0.95 15
#+END_SRC

**** Training on Data
We are using deepspeech.torch here to train on the data. We expect the
data to be mounted on /data.

#+BEGIN_SRC sh :tangle scripts/deepspeech-data-train.sh
set -x
set -e

cd ~/projects/CTCSpeechRecognition/
th MakeLMDB.lua -rootPath /data/data/big \
   -lmdbPath /data/data/big_lmdb \
   -windowSize 0.02 \
   -stride 0.01 \
   -sampleRate 16000 \
   -audioExtension wav \
   -processes $(nproc)

th Train.lua -epochSave \
   -learningRateAnnealing 1.1 \
   -trainingSetLMDBPath /data/data/big_lmdb/train/ \
   -validationSetLMDBPath /data/data/big_lmdb/dev/ \
   -nGPU 8 \
   -logsTrainPath /data/logs/deepspeech-big/TrainingLoss/ \
   -logsValidationPath /data/logs/deepspeech-big/ValidationScores/ \
   -modelTrainingPath /data/models/deepspeech-big/ \
   -epochs 500 \
   -learningRate 0.01 \
   -maxNorm 20 \
   -momentum 0.9 \
   -batchSize 32 \
   -validationBatchSize 32 \
   -permuteBatch
#+END_SRC

** Screen
GNU screen allows one to open a terminal session and persist it before
logging out of the server.

Secure copy this screen configuration into the home directory of the
server.

#+BEGIN_SRC screen :tangle data/.screenrc
# GNU Screen - main configuration file

# Allow bold colors - necessary for some reason
attrcolor b ".I"

# Tell screen how to set colors. AB = background, AF=foreground
termcapinfo xterm 'Co#256:AB=\E[48;5;%dm:AF=\E[38;5;%dm'

# Enables use of shift-PgUp and shift-PgDn
termcapinfo xterm|xterms|xs|rxvt ti@:te@

# Erase background with current bg color
defbce "on"

# Enable 256 color term
term xterm-256color

# Cache 30000 lines for scroll back
defscrollback 30000

hardstatus alwayslastline

# Very nice tabbed colored hardstatus line
hardstatus string '%{= Kd} %{= Kd}%-w%{= Kr}[%{= KW}%n %t%{= Kr}]%{= Kd}%+w %-= %{KG} %H%{KW}|%{KY}%101`%{KW}|%D %M %d %Y%{= Kc} %C%A%{-}'

# change command character from ctrl-a to ctrl-b (emacs users may want this)
escape ^Bb

# Hide hardstatus: ctrl-a f
bind f eval "hardstatus ignore"

# Show hardstatus: ctrl-a F
bind F eval "hardstatus alwayslastline"
#+END_SRC

** Cleanup
*** Address-space
#+BEGIN_SRC sh :tangle scripts/cleanup-addresses.sh :var name=name
assocIds=$(aws ec2 describe-addresses --profile ${name} --output text --query "Addresses[*].AssociationId")
for a in assocIds; do
    aws ec2 disassociate-address --association-id ${a} --profile ${name}
    aws ec2 release-address --allocation-id ${a} --profile ${name}
done
#+END_SRC

*** Instances
#+BEGIN_SRC sh :tangle scripts/cleanup-instances.sh :var name=name
instances=$(aws ec2 describe-instances --profile ${name} --output text --query "Reservations[*].Instances[*].InstanceId")
for i in instances; do
    aws ec2 terminate-instances --instance-ids ${i} --profile ${name}
    aws ec2 wait instance-terminated --instance-ids ${i} --profile ${name}
done
#+END_SRC

*** Security groups
#+BEGIN_SRC sh :tangle scripts/cleanup-security-group.sh :var name=name
groups=$(aws ec2 describe-security-groups --profile ${name} --output text --filter "Name=group-name,Values=${name}-security-group" --query "SecurityGroups[*].GroupId")
for g in groups; do
    aws ec2 delete-security-group --group-id ${s} --profile ${name}
done
#+END_SRC

*** Route Tables
#+BEGIN_SRC sh :tangle scripts/cleanup-route-tables.sh :var name=name
associations=$(aws ec2 describe-route-tables --profile ${name} --output text --filter "Name=association.main,Values=false" --query "RouteTables[*].Associations[*].RouteTableAssociationsId")
for a in associations; do
    aws ec2 disassociate-route-table --association-id ${a} --profile ${name}
done

tables=$(aws ec2 describe-route-tables --profile ${name} --output text --filter "Name=association.main,Values=false" --query "RouteTables[*].RouteTableId")
for t in tables; do
    aws ec2 delete-route-table --route-table-id ${t} --profile ${name}
done
#+END_SRC

*** Internet Gateways
#+BEGIN_SRC sh :tangle scripts/cleanup-internet-gateways.sh :var name=name
vpcs=$(aws ec2 describe-internet-gateways --profile ${name} --output text --filter "Name=tag:Name,Values=${name}-subnet" --query "InternetGateways[*].Attachments[*].VpcId")
igws=$(aws ec2 describe-internet-gateways --profile ${name} --output text --filter "Name=tag:Name,Values=${name}-subnet" --query "InternetGateways[*].InternetGatewayId")
vis=$(paste <(echo "$vpcs") <(echo "$igws") --delimiters ';')

for vi in vis; do
    IFS=';' read -ra pair <<< "${vi}"
    v=${pair[0]}
    i=${pair[1]}
    echo "${v}, ${i}"
done

#+END_SRC
** Utilities
:PROPERTIES:
:CUSTOM_ID: sec:utilities
:END:

*** Attach another volume to an EC2 instance
:PROPERTIES:
:CUSTOM_ID: sec:util-attach-vol
:END:

We may need to attach larger volumes to store data and compute
outputs. We can add another volume to an existing EC2 instance. The
following script accepts three parameters:
 - S: the size in GB
 - I: the instance-id
 - D: the device name

#+BEGIN_SRC sh :tangle scripts/new-volume.sh :var az=az :var name=name :var scriptsDir=scriptsDir
S=$1
I=$2
D=$3

volumeId=$(aws ec2 create-volume \
               --profile ${name} \
               --size ${S} \
               --volume-type gp2 \
               --availability-zone ${az} \
               --query "VolumeId" \
               --output text)

aws ec2 create-tags --resources ${volumeId} --tags Key=Name,Value=${name}-volume --profile ${name}
${scriptsDir}/tag4billing.sh ${volumeId}

aws ec2 attach-volume \
    --profile ${name} \
    --volume-id ${volumeId} \
    --instance-id ${I} \
    --device ${D}
#+END_SRC

Once the volume is attached, we need to create a file system and mount it.

Let's first check whether it has been attached.

#+BEGIN_SRC sh
lsblk
#+END_SRC

Now, we can create a file system and mount the device

#+BEGIN_SRC sh :tangle scripts/mount.sh
D=$1
M=$2
sudo mkfs -t ext4 ${D}
sudo mkdir ${M}
sudo mount ${D} ${M}
#+END_SRC

In order to persist this mount point we need to add it to /etc/fstab

#+BEGIN_SRC sh
sudo cp /etc/fstab /etc/fstab.orig
#+END_SRC

The fstab entry follows this format:

device_name  mount_point  file_system_type  fs_mntops  fs_freq  fs_passno

E.g., fs_mntops=defaults,nofail fs_freq=0 fs_passno=2

*** Investigate spot price history
:PROPERTIES:
:CUSTOM_ID: sec:util-price-hist
:END:

The following script iterates through the availability zones of the
current region and prints a statistical summary of the spot price
history.

#+BEGIN_SRC sh :tangle scripts/spot-price-summary.sh :var instanceType=instanceType
azs=$(aws cloudhsm list-available-zones --output text --query 'AZList')
for az in ${azs}; do
    echo ${az}
    aws ec2 describe-spot-price-history \
        --instance-types ${instanceType} \
        --availability-zone ${az} \
        --filters "Name=product-description,Values=Linux/UNIX" \
        --output json --query "SpotPriceHistory[*].SpotPrice" \
        |jq -r '.[]'\
        |python -c "import sys, numpy as np, pandas as pd; df = pd.read_csv(sys.stdin, header=None, names=['price']); print(df.price.describe(np.arange(0,1,0.1)+0.1))"
done
#+END_SRC

#+BEGIN_SRC sh :tangle scripts/spot-price-timeseries.sh :var instanceType=instanceType
az=$1
echo ${az}
aws ec2 describe-spot-price-history \
    --instance-types ${instanceType} \
    --availability-zone ${az} \
    --filters "Name=product-description,Values=Linux/UNIX" \
    --output text \
    |tr "\t" ","|cut -d, -f5,6 \
    |python -c "import sys, numpy as np, pandas as pd, matplotlib.pyplot as plt; df = pd.read_csv(sys.stdin, header=None, names=['price','t'], infer_datetime_format=True, parse_dates=['t']); ax = df.plot(x='t',y='price'); fig = ax.get_figure(); fig.savefig('az-timeseries.png');"
#+END_SRC

#+BEGIN_SRC python :tangle scripts/spot-price.py
import argparse

import numpy as np
import pandas as pd


def clean(priceHistory):
    df = pd.read_csv(
        priceHistory,
        header=None,
        names=['price','t'],
        infer_datetime_format=True,
        parse_dates=['t'])
    df.t = df.t.map(lambda t: t.strftime('%Y-%m-%d %H:%M'))
    df = df.groupby(['t'], sort=True, as_index=True)['price'].max()
    df.index = pd.to_datetime(df.index)
    idx = pd.date_range(df.index.min(), df.index.max(), freq='Min', name='t')
    df = df.reindex(idx, method='ffill').reset_index()
    return(df)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('priceHistory', type=str,
                        help='Path to price history file')
    parser.add_argument('az', type=str,
                        help='The AWS availability zone')
    args = parser.parse_args()
    df = clean(args.priceHistory)
    df.pricePerMinute = df.price/60.0
    hours = np.array([1, 2, 4, 8, 24, 48, 72, 168, 336, 672])

    print('az,hours,price,avgPricePerHour')
    for h in hours:
        price = df.pricePerMinute[-h*60:].sum()
        print('{3:s},{0:f},{1:f},{2:f}'.format(h, price, price/h, args.az))
#+END_SRC

We would like to iterate over specified regions and their availability
zones to compute a summary of spot prices assuming an EC2 instance was
running.

The following script takes as an input a region and computes prices
over all availability zones within it.

#+BEGIN_SRC sh :tangle scripts/spot-price-comparison.sh :var scriptsDir=scriptsDir :var dataDir=dataDir :var instanceType=instanceType
region=$1
azs=$(aws --region ${region} cloudhsm list-available-zones --output text --query 'AZList')

mkdir -p ${dataDir}/spot-prices

for az in ${azs}; do
    echo ${az}
    aws --region ${region} ec2 describe-spot-price-history \
        --instance-types ${instanceType} \
        --availability-zone ${az} \
        --filters "Name=product-description,Values=Linux/UNIX" \
        --output text \
        |tr "\t" ","|\
        cut -d, -f6,5 \
            > ${dataDir}/spot-prices/${instanceType}-spot-price-history-${az}.csv

    python ${scriptsDir}/spot-price.py ${dataDir}/spot-prices/${instanceType}-spot-price-history-${az}.csv ${az} > ${dataDir}/spot-prices/${instanceType}-spot-price-history-${az}-summary.csv
done
rm ${dataDir}/spot-prices/${instanceType}-spot-price-history-${region}-summary.csv
cat ${dataDir}/spot-prices/${instanceType}-spot-price-history-${region}*-summary.csv \
    | awk -F, '{if (NR==1) {print $0} else {if ($1 != "az") {print $0}}}' \
          > ${dataDir}/spot-prices/${instanceType}-spot-price-history-${region}-summary.csv
#+END_SRC

The following script can be used to visualise the spot price summary,
which is implemented in R using ggplot2.

#+BEGIN_SRC R :tangle scripts/plot-spot-price-summary.R
require(ggplot2)
require(gridExtra)

args <- commandArgs(trailingOnly = TRUE)

df <- read.csv(args[1], header=T)

p1 <- ggplot(df, aes(x=hours, y=price)) + geom_line(aes(color=az)) + theme_bw() + theme(legend.position="bottom")
p2 <- ggplot(df, aes(x=hours, y=avgPricePerHour)) + geom_line(aes(color=az)) + theme_bw()

#extract legend
#https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
g_legend <- function(a.gplot) {
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)
}

pdf(args[2], onefile=F)
mylegend <- g_legend(p1)
p3 <- grid.arrange(
    arrangeGrob(p1 + theme(legend.position="none"),
                p2 + theme(legend.position="none"),
                nrow=1),
    mylegend, nrow=2, heights=c(10, 1))
dev.off()
#+END_SRC

#+BEGIN_SRC sh :tangle scripts/plot-spot-price-summary.sh :var scriptsDir=scriptsDir :var dataDir=dataDir :var instanceType=instanceType
region=$1
Rscript ${scriptsDir}/plot-spot-price-summary.R ${dataDir}/spot-prices/${instanceType}-spot-price-history-${region}-summary.csv ${dataDir}/spot-prices/${instanceType}-spot-price-history-${region}-summary.pdf
#+END_SRC
